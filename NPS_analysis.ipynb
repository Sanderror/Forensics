{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2dd2ee3-b7cc-4829-8343-676aca6c9da6",
   "metadata": {},
   "source": [
    "# NPS Analysis\n",
    "This notebook will demonstrate how we used the crawled data from the dark web in order to make predictions for unknown NPS names.\n",
    "\n",
    "The notebook consists of the following sections:\n",
    "\n",
    "## Table of Contents\n",
    "- [0. Libraries](#0.-Libraries)\n",
    "- [1. Preprocessing](#1.-Preprocessing)\n",
    "- [2. Training Dataset](#2.-Training-Dataset)\n",
    "- [3. Candidates](#3.-Candidates)\n",
    "- [4. Model Training](#4.-Model-Training)\n",
    "- [5. Predictions](#5.-Predictions)\n",
    "- [6. Dashboard Preparation](#6.-Dashboard-Preparation)\n",
    "- [Appendix: Vendor Predictions](#Appendix:-Vendor-Predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ec64b7-0319-4c3b-bdf8-d2f159d250fe",
   "metadata": {},
   "source": [
    "# 0. Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5393615-c2ec-478e-a847-2b8538132dd6",
   "metadata": {},
   "source": [
    "Here all libraries needed to run the dashboard are imported. Run the cell below to install the required packages first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf95efa8-8d0e-468a-bd25-96a0cfd2e472",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "987aa06a-3326-4f15-92d8-f4c475f0c8b0",
   "metadata": {
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-31 23:06:07.877 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from collections import defaultdict\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, classification_report, confusion_matrix\n",
    "import ast\n",
    "import time\n",
    "from collections import Counter\n",
    "import pickle\n",
    "import streamlit as st\n",
    "from st_aggrid import GridOptionsBuilder, AgGrid, GridUpdateMode\n",
    "import altair as alt\n",
    "import streamlit.components.v1 as components\n",
    "from lime.lime_text import LimeTextExplainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31cde573-25e8-4e89-a7d1-0dd0204ef46e",
   "metadata": {},
   "source": [
    "# 1. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe1046f-b6bb-4c42-a0fa-54cc74cf9e4f",
   "metadata": {},
   "source": [
    "In this section, the crawled data is loaded in and cleaned for further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f236b776-e4c9-4029-8a3f-3ba11b5a4f75",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    '''Function to clean the raw messages in the dataset'''\n",
    "    text = re.sub(r'<.*?>', ' ', text)               # Remove HTML\n",
    "    text = re.sub(r'\\n', ' ', text)                  # Remove \\n for spaces\n",
    "    text = re.sub(r'http\\S+', ' ', text)             # Remove URLs\n",
    "    text = re.sub(r'@\\w+', ' ', text)                # Remove usernames\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s\\-]', ' ', text)    # Remove non-letters and non-numbers\n",
    "    text = re.sub(r'\\s-\\s?|\\s?-\\s', ' ', text)       # Remove dashes surrounded by spaces\n",
    "    text = re.sub(r'\\s+', ' ', text)                 # Remove double whitespaces\n",
    "    return text.lower().strip()                      # Convert to lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb0fdb7a-bd9d-4d7e-918e-4656f9af4fa7",
   "metadata": {
    "is_executing": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Message</th>\n",
       "      <th>MessageId</th>\n",
       "      <th>MessageTitle</th>\n",
       "      <th>User</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Subdread</th>\n",
       "      <th>NumberOfComments</th>\n",
       "      <th>CommentToF</th>\n",
       "      <th>cleaned_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Just giving a shout out to Cheshirecat82. Just...</td>\n",
       "      <td>62dc896a6d0c1b88cf90</td>\n",
       "      <td>Cheshirecat82</td>\n",
       "      <td>/u/ecto</td>\n",
       "      <td>2023-11-05 20:35:00</td>\n",
       "      <td>/d/Psychedelics</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>just giving a shout out to cheshirecat82 just ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How come there's nobody whose shared the REAL ...</td>\n",
       "      <td>55020c8fbfe69b0f722b</td>\n",
       "      <td>The Birch method with pseudoephedrine precurso...</td>\n",
       "      <td>/u/Ghwbushsr</td>\n",
       "      <td>2025-03-12 00:56:00</td>\n",
       "      <td>/d/DrugManufacture</td>\n",
       "      <td>17</td>\n",
       "      <td>False</td>\n",
       "      <td>how come there s nobody whose shared the real ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I 100% agree OP. Birtch reeduction all the way...</td>\n",
       "      <td>55020c8fbfe69b0f722b</td>\n",
       "      <td>The Birch method with pseudoephedrine precurso...</td>\n",
       "      <td>/u/Thehighlow</td>\n",
       "      <td>2025-03-12 01:19:00</td>\n",
       "      <td>/d/DrugManufacture</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>i 100 agree op birtch reeduction all the way i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I understand no one wants to tell someone who ...</td>\n",
       "      <td>55020c8fbfe69b0f722b</td>\n",
       "      <td>The Birch method with pseudoephedrine precurso...</td>\n",
       "      <td>/u/UnpaintedSinner</td>\n",
       "      <td>2025-03-12 02:03:00</td>\n",
       "      <td>/d/DrugManufacture</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>i understand no one wants to tell someone who ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The thing is fucks like Uncle Fester and miste...</td>\n",
       "      <td>55020c8fbfe69b0f722b</td>\n",
       "      <td>The Birch method with pseudoephedrine precurso...</td>\n",
       "      <td>/u/Ghwbushsr</td>\n",
       "      <td>2025-03-15 01:50:00</td>\n",
       "      <td>/d/DrugManufacture</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>the thing is fucks like uncle fester and miste...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Message             MessageId  \\\n",
       "0  Just giving a shout out to Cheshirecat82. Just...  62dc896a6d0c1b88cf90   \n",
       "1  How come there's nobody whose shared the REAL ...  55020c8fbfe69b0f722b   \n",
       "2  I 100% agree OP. Birtch reeduction all the way...  55020c8fbfe69b0f722b   \n",
       "3  I understand no one wants to tell someone who ...  55020c8fbfe69b0f722b   \n",
       "4  The thing is fucks like Uncle Fester and miste...  55020c8fbfe69b0f722b   \n",
       "\n",
       "                                        MessageTitle                User  \\\n",
       "0                                      Cheshirecat82             /u/ecto   \n",
       "1  The Birch method with pseudoephedrine precurso...        /u/Ghwbushsr   \n",
       "2  The Birch method with pseudoephedrine precurso...       /u/Thehighlow   \n",
       "3  The Birch method with pseudoephedrine precurso...  /u/UnpaintedSinner   \n",
       "4  The Birch method with pseudoephedrine precurso...        /u/Ghwbushsr   \n",
       "\n",
       "             Timestamp            Subdread  NumberOfComments  CommentToF  \\\n",
       "0  2023-11-05 20:35:00     /d/Psychedelics                 0       False   \n",
       "1  2025-03-12 00:56:00  /d/DrugManufacture                17       False   \n",
       "2  2025-03-12 01:19:00  /d/DrugManufacture                 0        True   \n",
       "3  2025-03-12 02:03:00  /d/DrugManufacture                 0        True   \n",
       "4  2025-03-15 01:50:00  /d/DrugManufacture                 0        True   \n",
       "\n",
       "                                     cleaned_message  \n",
       "0  just giving a shout out to cheshirecat82 just ...  \n",
       "1  how come there s nobody whose shared the real ...  \n",
       "2  i 100 agree op birtch reeduction all the way i...  \n",
       "3  i understand no one wants to tell someone who ...  \n",
       "4  the thing is fucks like uncle fester and miste...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('drugs_data.csv')\n",
    "# Clean the messages in the dataset\n",
    "df['cleaned_message'] = df['Message'].astype(str).apply(clean_text)\n",
    "# Drop all the promotion messages that are spam and therefore lead to biased results\n",
    "df = df.drop_duplicates(subset=['Message', 'User']).reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3650564c-d2dd-40f9-b4f1-abaea9a1f707",
   "metadata": {},
   "source": [
    "# 2. Training Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8321dbf5-9525-46f8-af1a-66acb7c6f3d6",
   "metadata": {},
   "source": [
    "In this section:\n",
    "* The <b>seed lists</b> will be obtained and created (for drugs, vendors and the negative class)\n",
    "* The <b>contexts</b> will be scraped from the messages using these seeds\n",
    "\n",
    "As described in the scientific deliverable, we use a drug seed list, a vendor seed list, and a negative seed list. In this way, we can obtain 3 different classes of contexts and can train a classifier afterwards on them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856c9652-ad73-432c-a71b-e4548487423f",
   "metadata": {},
   "source": [
    "## 2.1 Seed lists"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30bf8c1-e099-476c-9141-692df36d7230",
   "metadata": {},
   "source": [
    "The 3 different seed lists will be obtained in the following way:\n",
    "* <b>Drugs</b>: Scrape the up-to-date list of known drug and NPS names and their aliases from [Talk To Frank](https://www.talktofrank.com/drugs-a-z).\n",
    "* <b>Vendors</b>: Manually created list by Google searching and LLM-prompting about known dark web marketplaces. This was extended with a list of vendor names obtained from the messages directly. We used RegEx to find Dread user names in messages and then checked whether they were mentioned in relation to selling drugs (e.g. \"The shrooms from /u/lilxan are delicious\")\n",
    "* <b>Negative</b>: In order to train a meaningful classifier, a Negative class was needed such that the model can learn when a context is drug-related and when it is not. [Del Vigna et al. (2016)](https://arxiv.org/abs/1609.06577) did not have a Negative class in their method, therefore we came up with a method ourselves. We looked up the most frequently occurring nouns in the dataset, computed how many times these nouns occurred in all messages, and then filtered these nouns from most frequent to less frequent. These were the most interesting nouns, because they would provide to the highest amount of training data for the negative class. Then we computed the amount of times a <b>known drug</b> or <b>known vendor</b> from the drugs and vendors seeds <b>occurred in the contexts of these most frequent nouns</b>. Then, for the top 30-ish most frequent nouns, we selected all nouns with a percentage of 18% or less of drugs occurring in their contexts as our negative class. The 18% is based on the fact that for this number, we managed to obtain roughly the same amount of negative contexts as drug contexts, which was desired to combat class imbalances. We extracted these contexts (of course without the contexts in which a known drug or known vendor occurs) and added these to the negative class.\n",
    "\n",
    "<b>NOTE</b>: We understand that the method for finding negative samples is not perfect, and has some disadvantages, with the most prominent one being that it is possible for <b>not yet known NPS names</b> to occur in the contexts of the negative class, which will degrade the performance of the classifier. However, we tried to mitigate this problem by filtering out the negative contexts with known drugs and vendors in there, so therefore we the negative class' contexts should in general contain less words related to drugs and vendors, and our method may still be able to find unknown NPS names (SPOILER: it does ;) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd6d3e31-13c0-4345-83e7-733618758864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape the known drug/NPS names from Talk to Frank\n",
    "content = requests.get('https://www.talktofrank.com/drugs-a-z')\n",
    "soup = BeautifulSoup(content.text)\n",
    "# Only scrape the drug names; no other information\n",
    "unfiltered_drug_list = [tag.get_text().lower() for tag in soup.find_all('span', {'class':'inverted'})]\n",
    "# Filter out drugs in the list of one letter or number 'H', 'C', '1', because this will lead to many contexts, and too many wrong contexts\n",
    "drug_list = [drug for drug in unfiltered_drug_list if len(drug) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e031f23-1b96-42ee-878c-96310bcbd184",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# Manually selected lists of marketplaces and vendors\n",
    "vendor_list = ['lilxan', 't4ps', 'justdefyreality', 'redbook', 'bbmc', 'bjohndoe70', 'adderallz', 'bluesconnect', 'mexicanconnection', \\\n",
    "              'peterchein', 'candyland', 'drugslocal', 'clandestiny', 'usapillpress', 'druggiebears', 'xanaxking']\n",
    "marketplace_list = ['archetyp', 'shell', 'aliexpress', 'dark0de', 'darkode', 'torrez', 'empire', 'hydra', 'torzon', \\\n",
    "               'dream', 'mgm', 'alibaba', 'abacus', 'tmg', 'gofish', 'aplhabay', 'dreammarket', 'silkroad', 'wethenorth', 'wtn']\n",
    "vendor_list.extend(marketplace_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c281650-cab7-412a-9f0e-153716fc3a0c",
   "metadata": {},
   "source": [
    "### Negative seeds\n",
    "<b>NOTE</b>: We have commented out the cells for the obtaining of the negative seeds because this takes a very long time to run... (talking in hours). The negative seeds that we have obtained from this procedure you can see below. If you still want to run the procedure for obtaining the negative seeds, you can uncomment the cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87507f97-491f-4317-87a4-42d1b9915551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The negative seeds have been obtained by the procedure described above\n",
    "neg_seeds = ['thanks', 'thank', 'money', 'account', 'days', 'post', 'orders', 'everything', 'things', 'man', 'everyone', 'customers', 'time', \n",
    "             'review', 'something', 'guy', 'anything', 'week', 'way', 'someone', 'order']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5cbf6b-5240-48ad-bdc3-6968d4fba2e5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# def extract_nouns(text, drug_list, vendor_list):\n",
    "#     '''Function to find potential negative seeds'''\n",
    "#     words = word_tokenize(text, preserve_line=True)\n",
    "#     tagged = pos_tag(words, lang='eng')  # Explicitly set lang\n",
    "#     return [word for word, tag in tagged if tag.startswith('NN') and word not in drug_list and word not in vendor_list and len(word) > 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6ef8a0-54d6-46e0-b26f-0ff82cde50ba",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# # Extract all potential candidates from all messages and count how often they occur\n",
    "# noun_dict = dict()\n",
    "# for text in df['cleaned_message']:\n",
    "#     nouns = extract_nouns(text, drug_list, vendor_list) \n",
    "#     for noun in nouns:\n",
    "#         if noun in noun_dict:\n",
    "#             noun_dict[noun] += 1\n",
    "#         else:\n",
    "#             noun_dict[noun] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d158776e-0c17-4f31-8249-32d2be4abbae",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# # Sort the list from most frequent potential seeds to least\n",
    "# sorted_words = sorted(noun_dict.items(), key=lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235e0b7e-0f86-4201-b810-880850904a90",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# # Loop over all these words from most frequent to least, and calulcate the ratio of drugs and vendors in their contexts\n",
    "# # This can take ages to run, advised is to stop it yourself after e.g. the top-30 seeds (also this will take a long time though)\n",
    "# for neg_seed, neg_count in sorted_words:\n",
    "#     count = 0\n",
    "#     for text in df['cleaned_message']:\n",
    "#         tokens = word_tokenize(text, preserve_line=True)\n",
    "#         for i, word in enumerate(tokens):\n",
    "#             if word == neg_seed:\n",
    "#                 start = max(i - 10, 0)\n",
    "#                 end = min(i + 11, len(tokens))\n",
    "#                 context = tokens[start:end]\n",
    "#                 for pot_drug in context:\n",
    "#                     if pot_drug in drug_list or pot_drug in vendor_list:\n",
    "#                         # print(f\"found {pot_drug} near {word}\")\n",
    "#                         count += 1\n",
    "#                         break\n",
    "#     print(f\"Word: {neg_seed} has {count} drugs in its context out of {neg_count}: {count/neg_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca48324-31b0-4403-8c5a-32e82f0ce2dd",
   "metadata": {},
   "source": [
    "## 2.2 Obtaining the contexts\n",
    "The next step was to use the seeds to find the contexts. That worked as follows:\n",
    "1. Loop through all cleaned messages in the dataset\n",
    "    2. Tokenize each message and loop through all words (<b>word_X</b>)\n",
    "        3. If <b>word_X</b> occurred in one of the seed lists do:\n",
    "            4. Grap the surrounding 20 words of <b>word_X</b>\n",
    "            5. Remove <b>word_X</b> from this string\n",
    "            6. Add these surrounding words as <b>context</b> for the class of the corresponding seed list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "659906c2-2c16-4afe-9d77-f28e6965fb72",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "def extract_contexts(text, seed_words, window=10):\n",
    "    '''Extract the contexts surrounding seeds'''\n",
    "    # Tokenize the message\n",
    "    words = word_tokenize(text, preserve_line=True)\n",
    "    word_list = []\n",
    "    contexts = []\n",
    "\n",
    "    # Obtain the contexts for the seeds\n",
    "    for i, word in enumerate(words):\n",
    "        if word in seed_words:\n",
    "            start = max(i - window, 0)\n",
    "            end = min(i + window + 1, len(words))\n",
    "            context = ' '.join(words[start:i]) + \" \" + ' '.join(words[i+1:end])\n",
    "            contexts.append(context)\n",
    "            word_list.append(word)\n",
    "    return contexts, word_list\n",
    "\n",
    "def extract_neg_contexts(text, seed_words, drug_list, vendor_list, window=10):\n",
    "    '''Extract the contexts surronding negative seeds'''\n",
    "    # Tokenize the message\n",
    "    words = word_tokenize(text, preserve_line=True)\n",
    "    contexts = []\n",
    "\n",
    "    # Obtain the contexts for the seeds\n",
    "    for i, word in enumerate(words):\n",
    "        drug_present = False\n",
    "        if word in seed_words:\n",
    "            start = max(i - window, 0)\n",
    "            end = min(i + window + 1, len(words))\n",
    "            temp_context = words[start:end]\n",
    "            # Only add contexts for negative class if there is no drug or vendor in the context\n",
    "            for potential_drug_vendor in temp_context:\n",
    "                if potential_drug_vendor in drug_list or potential_drug_vendor in vendor_list:\n",
    "                    drug_present = True\n",
    "            if not drug_present:\n",
    "                context = ' '.join(words[start:i]) + \" \" + ' '.join(words[i+1:end])\n",
    "                contexts.append(context)\n",
    "    return contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b97a665c-6e58-4e9a-8b64-d7027943c76b",
   "metadata": {
    "is_executing": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>term</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>reeduction all the way i used liquid my own am...</td>\n",
       "      <td>gas</td>\n",
       "      <td>substance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ephedrine intermittently until it s ready to c...</td>\n",
       "      <td>juice</td>\n",
       "      <td>substance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>someone who is unexperienced how to begin lear...</td>\n",
       "      <td>meth</td>\n",
       "      <td>substance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>book would be worth some money a full guide co...</td>\n",
       "      <td>meth</td>\n",
       "      <td>substance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i know a really good process to go from pseudo...</td>\n",
       "      <td>pills</td>\n",
       "      <td>substance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284987</th>\n",
       "      <td>this is the strangest but i like it</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284988</th>\n",
       "      <td>testers off amazon and i will say cozy boy and...</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284989</th>\n",
       "      <td>t bullshitting ended up failing a drug test ar...</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284990</th>\n",
       "      <td>this is what i heard experienced and i really ...</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284991</th>\n",
       "      <td>but i don t know if i can trust them</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284992 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  context   term      label\n",
       "0       reeduction all the way i used liquid my own am...    gas  substance\n",
       "1       ephedrine intermittently until it s ready to c...  juice  substance\n",
       "2       someone who is unexperienced how to begin lear...   meth  substance\n",
       "3       book would be worth some money a full guide co...   meth  substance\n",
       "4       i know a really good process to go from pseudo...  pills  substance\n",
       "...                                                   ...    ...        ...\n",
       "284987                this is the strangest but i like it  other      other\n",
       "284988  testers off amazon and i will say cozy boy and...  other      other\n",
       "284989  t bullshitting ended up failing a drug test ar...  other      other\n",
       "284990  this is what i heard experienced and i really ...  other      other\n",
       "284991              but i don t know if i can trust them   other      other\n",
       "\n",
       "[284992 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For the drugs and vendors, we store both the contexts as well as the terms based on which the contexts where found (for negative this is not interesting)\n",
    "drugs_contexts = []\n",
    "drugs_named = []\n",
    "vendors_contexts = []\n",
    "vendors_named = []\n",
    "negative_contexts = []\n",
    "\n",
    "# Loop over all messages and find the contexts for all seeds\n",
    "for message in df['cleaned_message']:\n",
    "    # Obtain the contexts for all classes for this message (if any)\n",
    "    context_drugs, drug_context_list = extract_contexts(message, drug_list)\n",
    "    context_vendors, vendor_context_list = extract_contexts(message, vendor_list)\n",
    "    context_negatives = extract_neg_contexts(message, neg_seeds, drug_list, vendor_list)\n",
    "\n",
    "    # Add the contexts to the lists for this message\n",
    "    if len(context_drugs) > 0:\n",
    "        drugs_contexts.extend(context_drugs)\n",
    "        drugs_named.extend(drug_context_list)\n",
    "    if len(context_vendors) > 0:\n",
    "        vendors_contexts.extend(context_vendors)\n",
    "        vendors_named.extend(vendor_context_list)\n",
    "    if len(context_negatives) > 0:\n",
    "        negative_contexts.extend(context_negatives)\n",
    "\n",
    "# Create a dataframe for each class and then add them together\n",
    "drug_df = pd.DataFrame(drugs_contexts, columns=['context'])\n",
    "drug_df['term'] = drugs_named\n",
    "drug_df['label'] = 'substance'\n",
    "vendor_df = pd.DataFrame(vendors_contexts, columns=['context'])\n",
    "vendor_df['label'] = 'vendor'\n",
    "vendor_df['term'] = vendors_named\n",
    "neg_df = pd.DataFrame(negative_contexts, columns=['context'])\n",
    "neg_df['label'] = 'other'\n",
    "neg_df['term'] = 'other'\n",
    "\n",
    "# Create the training dataset\n",
    "df_train = pd.concat([drug_df, vendor_df, neg_df], ignore_index=True)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf6f63d-6659-427f-9dc5-179c0b83126e",
   "metadata": {},
   "source": [
    "# 3. Candidates\n",
    "\n",
    "In this section, we obtain the candidate NPS names and their contexts as follows:\n",
    "* Extract all unique nouns from all messages (these are our candidate NPS names)\n",
    "* Loop over all candidate NPS names and scrape their contexts\n",
    "\n",
    "<b>NOTE</b>: This method for finding candidate NPS names is functional, because the set of actual unknown NPS names will always be a subset of the set of nouns in all messages (because any NPS name should be a noun). However, this finds A LOT of candidate NPS names (almost 75.000), which means that the process of obtaining them and then also scraping all their contexts can take a little while... Around (15+30=) 45 minutes ish... Because of this, we have also allowed the possibility to just simply load the datasets in from a pre-saved version. This will be exactly the same content as if you were to run the code yourself, so it is just to save you time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00b74687-ae96-4b57-8272-e1c71ca25931",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_all_nouns(df, drug_list, vendor_list, neg_list):\n",
    "    '''Function to find all words occurring at least once as a noun in the messages; these will be our candidate NPS names'''\n",
    "    noun_set = set()\n",
    "    # Loop through all messages\n",
    "    for text in df['cleaned_message']:\n",
    "        \n",
    "        # Use nltk's pos_tag to find nouns\n",
    "        words = word_tokenize(text, preserve_line=True)\n",
    "        tagged = pos_tag(words, lang='eng')  # Explicitly set lang\n",
    "        for word, tag in tagged:\n",
    "            # If it's already in the set with nouns, then we can continue\n",
    "            if word in noun_set:\n",
    "                continue\n",
    "            # Otherwise we will add it to the set of nouns if it is a noun (and it does not occur in the seed lists already)\n",
    "            else:\n",
    "                if tag.startswith('NN') and word not in drug_list and word not in vendor_list and word not in neg_list and len(word) > 2:\n",
    "                    noun_set.add(word)\n",
    "    return list(noun_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "220310ca-5546-4b5d-a62a-e44e11f4caec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74909"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract candidate NPS names list beforehand (can take 15 minutes or so to run)\n",
    "noun_list = extract_all_nouns(df, drug_list, vendor_list, neg_seeds)\n",
    "len(noun_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e7ff02c3-6ec1-4397-8d73-192b578e6464",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74909"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# IF YOU DO NOT WANT TO RUN THE CODE ABOVE\n",
    "with open(\"candidate_seeds.pkl\", 'rb') as f:\n",
    "    noun_list = pickle.load(f)\n",
    "len(noun_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "138dc796-71c5-4ba7-9a2c-c1ff384f1970",
   "metadata": {
    "is_executing": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# THIS CELL CAN TAKE 30 MINUTES TO RUN...\n",
    "candidate_contexts = defaultdict(list)\n",
    "\n",
    "# loop over all messages\n",
    "for text in df['cleaned_message']:\n",
    "    # Converts message to tokens and finds the candidate NPS names in the message (intersection of tokens and noun_list)\n",
    "    tokens = word_tokenize(text, preserve_line=True)\n",
    "    nouns = set(tokens) & set(noun_list)\n",
    "\n",
    "    # Loops through all words in message and for the candidate NPS names it extracts the contexts\n",
    "    for i, word in enumerate(tokens):\n",
    "        for noun in nouns:\n",
    "            if word == noun:\n",
    "                start = max(0, i - 10)\n",
    "                end = min(len(tokens), i + 11)\n",
    "                context = ' '.join(tokens[start:i]) + \" \" + ' '.join(tokens[i+1:end])\n",
    "                candidate_contexts[noun].append(context)\n",
    "\n",
    "# Add the candidates with all their scraped contexts to a dataframe\n",
    "candidate_data = [(term, context) for term, contexts in candidate_contexts.items() for context in contexts]\n",
    "candidate_df = pd.DataFrame(candidate_data, columns=['term', 'context'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fa2fcc-9c48-4f3b-b056-d46b8732c108",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# IF YOU DO NOT WANT TO RUN THE CODE ABOVE\n",
    "candidate_df = pd.read_csv('candidate_predictions_final.csv')[['term', 'context']]\n",
    "candidate_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1bf505-e530-4021-920f-69495a128454",
   "metadata": {},
   "source": [
    "# 4. Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffaf8bf4-68aa-4b40-9669-a306635e928e",
   "metadata": {},
   "source": [
    "In this section, we train the model\n",
    "* First we split the training dataset into a train and test set\n",
    "* Then the contexts are Tf-idf vectorized of the train set and a logistic regresssion model is trained\n",
    "* Then we assess the model's performance on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e2e90c41-e130-4542-b8e5-59cfc2e15dd0",
   "metadata": {
    "is_executing": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.0830500125885\n"
     ]
    }
   ],
   "source": [
    "# We split the data randomly into a 80% train 20% test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_train['context'], df_train['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "# We create a pipeline that first performs tf-idf vectorizing on the contexts and then trains a logistic regression model\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words='english')),\n",
    "    ('clf', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "# We fit the model on the train set\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cadc5ea2-840c-4e72-82af-12589f442aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7697\n",
      "Precision (macro): 0.7191\n",
      "Recall (macro): 0.5969\n",
      "F1 Score (macro): 0.6244\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       other       0.76      0.87      0.81     30439\n",
      "   substance       0.79      0.71      0.75     23629\n",
      "      vendor       0.60      0.21      0.31      2931\n",
      "\n",
      "    accuracy                           0.77     56999\n",
      "   macro avg       0.72      0.60      0.62     56999\n",
      "weighted avg       0.77      0.77      0.76     56999\n",
      "\n",
      "Confusion Matrix:\n",
      " [[26587  3668   184]\n",
      " [ 6742 16665   222]\n",
      " [ 1572   738   621]]\n"
     ]
    }
   ],
   "source": [
    "# Here we calculate several performance evaluation metrics on our trained model\n",
    "\n",
    "# Obtain the predictions\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Overall Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Precision, Recall, and F1 Score (macro)\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "# Full classification report on test and predictions\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Print results\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision (macro): {precision:.4f}\")\n",
    "print(f\"Recall (macro): {recall:.4f}\")\n",
    "print(f\"F1 Score (macro): {f1:.4f}\")\n",
    "print(\"\\nClassification Report:\\n\", report)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39493b17-56c1-4518-b4fa-61bae546b4de",
   "metadata": {},
   "source": [
    "# 5. Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6726ce7-5b3b-4b86-8600-1ae734a1a127",
   "metadata": {},
   "source": [
    "Finally, in this section, we will make the predictions on what might be unknown NPS names. That works as follows:\n",
    "* First, we predict every context of every candidate seed using the trained Logistic Regression model\n",
    "* This gives us a probability for the context being that of a substance (drug), vendor, or other (negative)\n",
    "* We extract for every candidate seed the known drugs in their contexts (this will be used in the dashboard later on)\n",
    "* Then, we <b>aggregate</b> the predicted probabilities for the drug class for each candidate (as well as the count of contexts for each candidate, and the top 10 most frequent occurring drugs in the candidate's contexts)\n",
    "* This list is sorted in descending order, which provides us with the candidate with the <b>highest probability of being a drug</b> at the top (note that this may only be present in 1 or very little contexts, so this is not necessarily our best prediction)\n",
    "\n",
    "In this way, we have obtained a list of almost <b>75.000</b> candidate NPS names with their associated probabilities of being an actual NPS/Drug! In the dashboard, filters are applied to this list to obtain a more accurate list of unknown NPS names (e.g. only show candidates that have at least occurred in 20 messages, have at least been used by 5 different users, and have a probability of being a NPS of at least 0.75)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d3d6760d-bd04-444d-9305-f100a9ddd9f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>context</th>\n",
       "      <th>prediction</th>\n",
       "      <th>prob_substance</th>\n",
       "      <th>prob_vendor</th>\n",
       "      <th>prob_other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>shout</td>\n",
       "      <td>just giving a out to cheshirecat82 just got a ...</td>\n",
       "      <td>substance</td>\n",
       "      <td>0.525836</td>\n",
       "      <td>0.020927</td>\n",
       "      <td>0.453237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shout</td>\n",
       "      <td>get into here mate but i ll give you a through pm</td>\n",
       "      <td>other</td>\n",
       "      <td>0.049611</td>\n",
       "      <td>0.022997</td>\n",
       "      <td>0.927392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>shout</td>\n",
       "      <td>out to the mod that posted it 2 years ago</td>\n",
       "      <td>other</td>\n",
       "      <td>0.109568</td>\n",
       "      <td>0.019599</td>\n",
       "      <td>0.870833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>shout</td>\n",
       "      <td>my china packs land 12 days or less every time...</td>\n",
       "      <td>other</td>\n",
       "      <td>0.153924</td>\n",
       "      <td>0.035803</td>\n",
       "      <td>0.810273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>shout</td>\n",
       "      <td>nah you can smoke and shake and bake you can e...</td>\n",
       "      <td>substance</td>\n",
       "      <td>0.924407</td>\n",
       "      <td>0.004375</td>\n",
       "      <td>0.071219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    term                                            context prediction  \\\n",
       "0  shout  just giving a out to cheshirecat82 just got a ...  substance   \n",
       "1  shout  get into here mate but i ll give you a through pm      other   \n",
       "2  shout          out to the mod that posted it 2 years ago      other   \n",
       "3  shout  my china packs land 12 days or less every time...      other   \n",
       "4  shout  nah you can smoke and shake and bake you can e...  substance   \n",
       "\n",
       "   prob_substance  prob_vendor  prob_other  \n",
       "0        0.525836     0.020927    0.453237  \n",
       "1        0.049611     0.022997    0.927392  \n",
       "2        0.109568     0.019599    0.870833  \n",
       "3        0.153924     0.035803    0.810273  \n",
       "4        0.924407     0.004375    0.071219  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtain the predictions for the contexts of the candidate seeds (can take 5 minutes to run)\n",
    "candidate_df['prediction'] = pipeline.predict(candidate_df['context'])\n",
    "candidate_df['prob_substance'] = pipeline.predict_proba(candidate_df['context'])[:, list(pipeline.classes_).index('substance')]\n",
    "candidate_df['prob_vendor'] = pipeline.predict_proba(candidate_df['context'])[:, list(pipeline.classes_).index('vendor')]\n",
    "candidate_df['prob_other'] = pipeline.predict_proba(candidate_df['context'])[:, list(pipeline.classes_).index('other')]\n",
    "candidate_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98bf32e4-1115-4c16-b2c6-d6f106924de6",
   "metadata": {},
   "source": [
    "### Find similar drugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "57ee14cc-4bf4-4c11-8d82-a1cf3b53c7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_drugs(context, drugs_list):\n",
    "    '''Function to extract the known drugs occurring in a candidate's context'''\n",
    "    present_drugs = [word for word in context.split() if word in drugs_list]\n",
    "    return present_drugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "784789c3-7aae-4d63-97dd-07e8a6f2c1af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>context</th>\n",
       "      <th>prediction</th>\n",
       "      <th>prob_substance</th>\n",
       "      <th>prob_vendor</th>\n",
       "      <th>prob_other</th>\n",
       "      <th>known_drugs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>shout</td>\n",
       "      <td>just giving a out to cheshirecat82 just got a ...</td>\n",
       "      <td>substance</td>\n",
       "      <td>0.525836</td>\n",
       "      <td>0.020927</td>\n",
       "      <td>0.453237</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shout</td>\n",
       "      <td>get into here mate but i ll give you a through pm</td>\n",
       "      <td>other</td>\n",
       "      <td>0.049611</td>\n",
       "      <td>0.022997</td>\n",
       "      <td>0.927392</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>shout</td>\n",
       "      <td>out to the mod that posted it 2 years ago</td>\n",
       "      <td>other</td>\n",
       "      <td>0.109568</td>\n",
       "      <td>0.019599</td>\n",
       "      <td>0.870833</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>shout</td>\n",
       "      <td>my china packs land 12 days or less every time...</td>\n",
       "      <td>other</td>\n",
       "      <td>0.153924</td>\n",
       "      <td>0.035803</td>\n",
       "      <td>0.810273</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>shout</td>\n",
       "      <td>nah you can smoke and shake and bake you can e...</td>\n",
       "      <td>substance</td>\n",
       "      <td>0.924407</td>\n",
       "      <td>0.004375</td>\n",
       "      <td>0.071219</td>\n",
       "      <td>[wash]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    term                                            context prediction  \\\n",
       "0  shout  just giving a out to cheshirecat82 just got a ...  substance   \n",
       "1  shout  get into here mate but i ll give you a through pm      other   \n",
       "2  shout          out to the mod that posted it 2 years ago      other   \n",
       "3  shout  my china packs land 12 days or less every time...      other   \n",
       "4  shout  nah you can smoke and shake and bake you can e...  substance   \n",
       "\n",
       "   prob_substance  prob_vendor  prob_other known_drugs  \n",
       "0        0.525836     0.020927    0.453237          []  \n",
       "1        0.049611     0.022997    0.927392          []  \n",
       "2        0.109568     0.019599    0.870833          []  \n",
       "3        0.153924     0.035803    0.810273          []  \n",
       "4        0.924407     0.004375    0.071219      [wash]  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This adds the known drugs to every candidate (can take some time to run too...)\n",
    "candidate_df['known_drugs'] = candidate_df['context'].apply(lambda x: extract_drugs(x, drug_list))\n",
    "candidate_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36cf17d3-72f6-4a76-92d9-bfb3a870ac75",
   "metadata": {},
   "source": [
    "### Aggregate probabilities to interpret candidates' likelihoods of being a NPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "273e82fa-9bf9-4477-9843-f710fb6db2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_top_known_drugs(drug_lists):\n",
    "    '''Function to obtain the top 10 most frequently occurring drugs in a candidate's context '''\n",
    "    # Flatten the list of lists and count frequencies\n",
    "    counter = Counter([drug for sublist in drug_lists for drug in sublist])\n",
    "    # Get the top 10 most common drugs\n",
    "    top_10 = [drug for drug, _ in counter.most_common(10)]\n",
    "    return top_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6a6775fe-82d8-4f32-9edf-3c6032924d8d",
   "metadata": {
    "is_executing": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>mean_prob</th>\n",
       "      <th>num_contexts</th>\n",
       "      <th>similar_drugs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60895</th>\n",
       "      <td>squidgame</td>\n",
       "      <td>0.999961</td>\n",
       "      <td>1</td>\n",
       "      <td>[xtc, mdma, ketamine]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>-ketamine</td>\n",
       "      <td>0.999928</td>\n",
       "      <td>2</td>\n",
       "      <td>[ketamine]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13159</th>\n",
       "      <td>colombiana</td>\n",
       "      <td>0.999919</td>\n",
       "      <td>3</td>\n",
       "      <td>[4-mmc, speed, paste, amphetamine, cocaine, ic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33998</th>\n",
       "      <td>isoproyl</td>\n",
       "      <td>0.999875</td>\n",
       "      <td>1</td>\n",
       "      <td>[bubble, alcohol, freebase, mixture]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18292</th>\n",
       "      <td>discrepency</td>\n",
       "      <td>0.999864</td>\n",
       "      <td>2</td>\n",
       "      <td>[mdma, cocaine, lsd]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              term  mean_prob  num_contexts  \\\n",
       "60895    squidgame   0.999961             1   \n",
       "62       -ketamine   0.999928             2   \n",
       "13159   colombiana   0.999919             3   \n",
       "33998     isoproyl   0.999875             1   \n",
       "18292  discrepency   0.999864             2   \n",
       "\n",
       "                                           similar_drugs  \n",
       "60895                              [xtc, mdma, ketamine]  \n",
       "62                                            [ketamine]  \n",
       "13159  [4-mmc, speed, paste, amphetamine, cocaine, ic...  \n",
       "33998               [bubble, alcohol, freebase, mixture]  \n",
       "18292                               [mdma, cocaine, lsd]  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aggregate the drug probabilities per candidate with the mean and sort them from most likely to be a drug to least likely\n",
    "term_scores = candidate_df.groupby('term').agg(mean_prob=('prob_substance','mean'), num_contexts=('prob_substance', 'count'), similar_drugs=('known_drugs', aggregate_top_known_drugs)).reset_index().sort_values(by='mean_prob', ascending=False)\n",
    "term_scores.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dad2ae7-2375-423d-8b83-adb2baeac94d",
   "metadata": {},
   "source": [
    "# 6. Dashboard Preparation\n",
    "We want to display our results in an interactive dashboard that can be used by Law Enforcement Agencies to investigate our predicted unknown NPS names in more detail. The dashboard will contain a few features that will be created here in this section:\n",
    "* <b>Similar known drugs</b>: This was already obtained in the previous section\n",
    "* <b>Number of messages</b>: The number of messages in which the candidate NPS occurred\n",
    "* <b>Number of users</b>: The number of unique users that used the candidate NPS in their messages\n",
    "\n",
    "A few files will be exported that will be used in the dashboard:\n",
    "* <b>Cleaned dataset</b>: The drugs dataset with the messages already cleaned for faster processing in the dashboard\n",
    "* <b>Term scores</b>: This is the main dataset with the predictions of candidates' likeliness of being a NPS\n",
    "* <b>Candidate dataset</b>: This dataset will be used to provide explanations for a certain candidate's context, why that context was predicted to be drug-related\n",
    "* <b>Pipeline as pickle</b>: This will also be used for the explanation providing, to use the model's weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "04deb15c-7c7d-4a2e-a8a4-01fcc08914cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Message</th>\n",
       "      <th>MessageId</th>\n",
       "      <th>MessageTitle</th>\n",
       "      <th>User</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Subdread</th>\n",
       "      <th>NumberOfComments</th>\n",
       "      <th>CommentToF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[just, giving, a, shout, out, to, cheshirecat8...</td>\n",
       "      <td>62dc896a6d0c1b88cf90</td>\n",
       "      <td>Cheshirecat82</td>\n",
       "      <td>/u/ecto</td>\n",
       "      <td>2023-11-05 20:35:00</td>\n",
       "      <td>/d/Psychedelics</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[how, come, there, s, nobody, whose, shared, t...</td>\n",
       "      <td>55020c8fbfe69b0f722b</td>\n",
       "      <td>The Birch method with pseudoephedrine precurso...</td>\n",
       "      <td>/u/Ghwbushsr</td>\n",
       "      <td>2025-03-12 00:56:00</td>\n",
       "      <td>/d/DrugManufacture</td>\n",
       "      <td>17</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[i, 100, agree, op, birtch, reeduction, all, t...</td>\n",
       "      <td>55020c8fbfe69b0f722b</td>\n",
       "      <td>The Birch method with pseudoephedrine precurso...</td>\n",
       "      <td>/u/Thehighlow</td>\n",
       "      <td>2025-03-12 01:19:00</td>\n",
       "      <td>/d/DrugManufacture</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[i, understand, no, one, wants, to, tell, some...</td>\n",
       "      <td>55020c8fbfe69b0f722b</td>\n",
       "      <td>The Birch method with pseudoephedrine precurso...</td>\n",
       "      <td>/u/UnpaintedSinner</td>\n",
       "      <td>2025-03-12 02:03:00</td>\n",
       "      <td>/d/DrugManufacture</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[the, thing, is, fucks, like, uncle, fester, a...</td>\n",
       "      <td>55020c8fbfe69b0f722b</td>\n",
       "      <td>The Birch method with pseudoephedrine precurso...</td>\n",
       "      <td>/u/Ghwbushsr</td>\n",
       "      <td>2025-03-15 01:50:00</td>\n",
       "      <td>/d/DrugManufacture</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Message             MessageId  \\\n",
       "0  [just, giving, a, shout, out, to, cheshirecat8...  62dc896a6d0c1b88cf90   \n",
       "1  [how, come, there, s, nobody, whose, shared, t...  55020c8fbfe69b0f722b   \n",
       "2  [i, 100, agree, op, birtch, reeduction, all, t...  55020c8fbfe69b0f722b   \n",
       "3  [i, understand, no, one, wants, to, tell, some...  55020c8fbfe69b0f722b   \n",
       "4  [the, thing, is, fucks, like, uncle, fester, a...  55020c8fbfe69b0f722b   \n",
       "\n",
       "                                        MessageTitle                User  \\\n",
       "0                                      Cheshirecat82             /u/ecto   \n",
       "1  The Birch method with pseudoephedrine precurso...        /u/Ghwbushsr   \n",
       "2  The Birch method with pseudoephedrine precurso...       /u/Thehighlow   \n",
       "3  The Birch method with pseudoephedrine precurso...  /u/UnpaintedSinner   \n",
       "4  The Birch method with pseudoephedrine precurso...        /u/Ghwbushsr   \n",
       "\n",
       "            Timestamp            Subdread  NumberOfComments  CommentToF  \n",
       "0 2023-11-05 20:35:00     /d/Psychedelics                 0       False  \n",
       "1 2025-03-12 00:56:00  /d/DrugManufacture                17       False  \n",
       "2 2025-03-12 01:19:00  /d/DrugManufacture                 0        True  \n",
       "3 2025-03-12 02:03:00  /d/DrugManufacture                 0        True  \n",
       "4 2025-03-15 01:50:00  /d/DrugManufacture                 0        True  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make the message into a list which will be used to count the number of messages and number of users that used a candidate NPS\n",
    "df_split_message = pd.read_csv(\"drugs_data.csv\", parse_dates=[\"Timestamp\"])\n",
    "df_split_message['Message'] = df_split_message['Message'].astype(str).apply(clean_text)\n",
    "df_split_message['Message'] = df_split_message['Message'].apply(lambda x: str(x.split(\" \")))\n",
    "df_split_message = df_split_message.drop_duplicates(subset=['Message', 'User']).reset_index(drop=True)\n",
    "df_split_message['Message'] = df_split_message['Message'].apply(ast.literal_eval)\n",
    "df_split_message.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "996770a9-3aaa-493c-a7a3-9aca92e46ac3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Explode the dataframe of user and messages on the message\n",
    "df_exploded = df_split_message[['User', 'Message']].explode('Message')\n",
    "\n",
    "# Group by words to then perform the counts of candidates\n",
    "word_groups = df_exploded.groupby('Message')\n",
    "\n",
    "# Now quickly get counts for terms\n",
    "results = []\n",
    "for term in term_scores['term']:\n",
    "    try:\n",
    "        group = word_groups.get_group(term.lower())\n",
    "        num_messages = group.index.nunique()\n",
    "        num_users = group['User'].nunique()\n",
    "    except KeyError:\n",
    "        num_messages = 0\n",
    "        num_users = 0\n",
    "    results.append((num_messages, num_users))\n",
    "\n",
    "# Add the results to the list with predicted NPS\n",
    "term_scores['num_messages'] = [r[0] for r in results]\n",
    "term_scores['num_users'] = [r[1] for r in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "55e8ff0d-505b-4c6e-ab06-6ac88dbc7f96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>mean_prob</th>\n",
       "      <th>num_contexts</th>\n",
       "      <th>similar_drugs</th>\n",
       "      <th>num_messages</th>\n",
       "      <th>num_users</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41230</th>\n",
       "      <td>metaphedrone</td>\n",
       "      <td>0.989311</td>\n",
       "      <td>33</td>\n",
       "      <td>[white, weed, hash, meth, crystal, ice, ketami...</td>\n",
       "      <td>29</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31700</th>\n",
       "      <td>hydrochloric</td>\n",
       "      <td>0.973559</td>\n",
       "      <td>145</td>\n",
       "      <td>[acid, gas, base, heroin, mixture, mdma, cocai...</td>\n",
       "      <td>109</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17880</th>\n",
       "      <td>diethylamide</td>\n",
       "      <td>0.961595</td>\n",
       "      <td>50</td>\n",
       "      <td>[acid, lsd, white, mixture, cocaine, drop, cry...</td>\n",
       "      <td>25</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27323</th>\n",
       "      <td>glacial</td>\n",
       "      <td>0.957358</td>\n",
       "      <td>34</td>\n",
       "      <td>[acid, alcohol, amphetamine, heroin, mixture, ...</td>\n",
       "      <td>28</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62160</th>\n",
       "      <td>sulphuric</td>\n",
       "      <td>0.952639</td>\n",
       "      <td>40</td>\n",
       "      <td>[acid, amphetamine, gas, base, white, glass, c...</td>\n",
       "      <td>30</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63293</th>\n",
       "      <td>tartaric</td>\n",
       "      <td>0.952593</td>\n",
       "      <td>41</td>\n",
       "      <td>[acid, meth, lsd, ketamine, methamphetamine, m...</td>\n",
       "      <td>27</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11353</th>\n",
       "      <td>champagne</td>\n",
       "      <td>0.952089</td>\n",
       "      <td>259</td>\n",
       "      <td>[mdma, xtc, pills, ketamine, rocks, cocaine, p...</td>\n",
       "      <td>148</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56416</th>\n",
       "      <td>s-isomer</td>\n",
       "      <td>0.951635</td>\n",
       "      <td>143</td>\n",
       "      <td>[ketamine, mdma, crystal, rocks, meth, ice, wh...</td>\n",
       "      <td>105</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62150</th>\n",
       "      <td>sulfuric</td>\n",
       "      <td>0.951433</td>\n",
       "      <td>157</td>\n",
       "      <td>[acid, base, mixture, gas, cocaine, drop, alco...</td>\n",
       "      <td>105</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32687</th>\n",
       "      <td>impurity</td>\n",
       "      <td>0.942276</td>\n",
       "      <td>267</td>\n",
       "      <td>[acid, cocaine, wash, alcohol, mxe, ketamine, ...</td>\n",
       "      <td>259</td>\n",
       "      <td>176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               term  mean_prob  num_contexts  \\\n",
       "41230  metaphedrone   0.989311            33   \n",
       "31700  hydrochloric   0.973559           145   \n",
       "17880  diethylamide   0.961595            50   \n",
       "27323       glacial   0.957358            34   \n",
       "62160     sulphuric   0.952639            40   \n",
       "63293      tartaric   0.952593            41   \n",
       "11353     champagne   0.952089           259   \n",
       "56416      s-isomer   0.951635           143   \n",
       "62150      sulfuric   0.951433           157   \n",
       "32687      impurity   0.942276           267   \n",
       "\n",
       "                                           similar_drugs  num_messages  \\\n",
       "41230  [white, weed, hash, meth, crystal, ice, ketami...            29   \n",
       "31700  [acid, gas, base, heroin, mixture, mdma, cocai...           109   \n",
       "17880  [acid, lsd, white, mixture, cocaine, drop, cry...            25   \n",
       "27323  [acid, alcohol, amphetamine, heroin, mixture, ...            28   \n",
       "62160  [acid, amphetamine, gas, base, white, glass, c...            30   \n",
       "63293  [acid, meth, lsd, ketamine, methamphetamine, m...            27   \n",
       "11353  [mdma, xtc, pills, ketamine, rocks, cocaine, p...           148   \n",
       "56416  [ketamine, mdma, crystal, rocks, meth, ice, wh...           105   \n",
       "62150  [acid, base, mixture, gas, cocaine, drop, alco...           105   \n",
       "32687  [acid, cocaine, wash, alcohol, mxe, ketamine, ...           259   \n",
       "\n",
       "       num_users  \n",
       "41230          8  \n",
       "31700         69  \n",
       "17880         24  \n",
       "27323         22  \n",
       "62160         19  \n",
       "63293         16  \n",
       "11353         62  \n",
       "56416         36  \n",
       "62150         65  \n",
       "32687        176  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example filter that can be used now to get more accurate candidate predictions\n",
    "term_scores[(term_scores['num_messages'] > 20) & (term_scores['num_users'] > 5) & (term_scores['mean_prob'] > 0.75)].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a3929654-c1b1-4705-8cf4-99e598ba5b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the list of candidates for the dashboard\n",
    "term_scores.to_csv('term_scores_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1c3703e7",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# Export the candidates with their original contexts dataset\n",
    "candidate_df.to_csv('candidate_predictions_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "16ec580c-ac9f-4c0f-956c-139b14c7acb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the pipeline to pickle file so it can be used in dashboard\n",
    "with open('pipeline_final.pkl', 'wb') as f:\n",
    "    pickle.dump(pipeline, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2726bea5-9beb-48b7-81e4-bcb63f73c17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a cleaned version of the dataset for the dashboard\n",
    "df_drugs_cleaned = pd.read_csv(\"drugs_data.csv\", parse_dates=[\"Timestamp\"])\n",
    "df_drugs_cleaned['Message'] = df_drugs_cleaned['Message'].astype(str).apply(clean_text)\n",
    "df_drugs_cleaned.to_csv(\"drugs_data_cleaned_final.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8ecae3-e9f0-44e7-9cdb-6816b408f57b",
   "metadata": {},
   "source": [
    "# Appendix: Vendor Predictions\n",
    "A small section of our report mentioned the potential future work for the identification of unknown vendors. This section shows the creation of the small list that was added in the report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "44a600ad-5ea6-4922-adf6-45088e1bf999",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>mean_prob</th>\n",
       "      <th>num_contexts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66340</th>\n",
       "      <td>treesntreats-empire</td>\n",
       "      <td>0.996334</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58895</th>\n",
       "      <td>silk3</td>\n",
       "      <td>0.993303</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33501</th>\n",
       "      <td>interociter</td>\n",
       "      <td>0.992170</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6277</th>\n",
       "      <td>bersculoni</td>\n",
       "      <td>0.989706</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19836</th>\n",
       "      <td>drugsinkuk</td>\n",
       "      <td>0.982691</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      term  mean_prob  num_contexts\n",
       "66340  treesntreats-empire   0.996334             1\n",
       "58895                silk3   0.993303             1\n",
       "33501          interociter   0.992170             1\n",
       "6277            bersculoni   0.989706             1\n",
       "19836           drugsinkuk   0.982691             1"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtain the predicted probabilities for vendors\n",
    "vendors = candidate_df.groupby('term').agg(mean_prob=('prob_vendor','mean'), num_contexts=('prob_vendor', 'count')).reset_index().sort_values(by='mean_prob', ascending=False)\n",
    "vendors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b5d423db-cab9-4087-a2b0-4248e7e0a7c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>mean_prob</th>\n",
       "      <th>num_contexts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15932</th>\n",
       "      <td>d9f66c249805799a90f8c57b</td>\n",
       "      <td>0.914405</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65847</th>\n",
       "      <td>tormarket</td>\n",
       "      <td>0.903145</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64450</th>\n",
       "      <td>themiddleman</td>\n",
       "      <td>0.894063</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22700</th>\n",
       "      <td>exoticpacks</td>\n",
       "      <td>0.888630</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16176</th>\n",
       "      <td>dankservices3</td>\n",
       "      <td>0.870804</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73658</th>\n",
       "      <td>yoururl</td>\n",
       "      <td>0.795792</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1194</th>\n",
       "      <td>addyinc0</td>\n",
       "      <td>0.795397</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19737</th>\n",
       "      <td>drpremiumexotic</td>\n",
       "      <td>0.783042</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62356</th>\n",
       "      <td>superwavey</td>\n",
       "      <td>0.762502</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55129</th>\n",
       "      <td>revews</td>\n",
       "      <td>0.762275</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24529</th>\n",
       "      <td>flipndays21</td>\n",
       "      <td>0.724648</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39705</th>\n",
       "      <td>madrids</td>\n",
       "      <td>0.719791</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23495</th>\n",
       "      <td>fastshippinggg</td>\n",
       "      <td>0.718313</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53866</th>\n",
       "      <td>realtreesntreats</td>\n",
       "      <td>0.713722</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61083</th>\n",
       "      <td>standin</td>\n",
       "      <td>0.703354</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           term  mean_prob  num_contexts\n",
       "15932  d9f66c249805799a90f8c57b   0.914405            16\n",
       "65847                 tormarket   0.903145             7\n",
       "64450              themiddleman   0.894063            60\n",
       "22700               exoticpacks   0.888630            12\n",
       "16176             dankservices3   0.870804             6\n",
       "73658                   yoururl   0.795792             6\n",
       "1194                   addyinc0   0.795397             6\n",
       "19737           drpremiumexotic   0.783042            40\n",
       "62356                superwavey   0.762502             6\n",
       "55129                    revews   0.762275             9\n",
       "24529               flipndays21   0.724648            20\n",
       "39705                   madrids   0.719791             7\n",
       "23495            fastshippinggg   0.718313             7\n",
       "53866          realtreesntreats   0.713722            61\n",
       "61083                   standin   0.703354             9"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Small inspection for report of predicted vendors\n",
    "vendors[(vendors['num_contexts'] > 5) & (vendors['mean_prob'] > 0.7)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
